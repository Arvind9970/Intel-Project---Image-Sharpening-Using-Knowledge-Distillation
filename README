Image Sharpening and Upscaling with Knowledge Distillation

This project implements a lightweight student CNN model for image sharpening and upscaling using PyTorch. It includes:

- Training on 16:9 aspect ratio image pairs.
- Perceptual + L1 loss with VGG16 features.
- ONNX model export and real-time inference using AMD GPUs via DirectML.
- Real-time screen capture upscaling with OpenCV, MSS, and ONNX Runtime.

Features

- Lightweight student model using bilinear upsampling.
- 360x640 to 720x1280 resolution upscaling for real-time screen content.
- Edge-aware sharpening for better text clarity.
- Export to ONNX for optimized deployment.
- Real-time preview of inference output using OpenCV GUI.
- AMD GPU acceleration via `torch-directml` and `onnxruntime-directml`.

Directory Structure

image_sharpening_project/
|
├── data/
│   └── input_images/        # Training images
|
├── Student_Model/
│   └── Using gpu working    # Main script
|
├── Output Test/             # Inference output images
└── student_model.onnx       # Exported ONNX model

Installation

Python dependencies:

pip install torch torchvision opencv-python mss onnx onnxruntime-directml pillow matplotlib scikit-learn tqdm

For AMD GPU Support:

Install `torch-directml` from the official PyTorch DirectML repo:

pip install torch-directml

Note: Only works on Windows with AMD GPUs supported by DirectML.

Usage

Run the main script and select one of the following modes:

python "Student_Model/Using gpu working"

Options:

1. Train More  
   Continue or start training from scratch using existing .png images.

2. View Output  
   Run the model on a few sample inputs and save visual results in `Output Test/`.

3. Export to ONNX  
   Exports the trained PyTorch model to ONNX for real-time inference.

4. Live Upscale  
   Capture a region of the screen (640x360), upscale to 1280x720, sharpen, and display.

Training Details

- Input: Downsampled image of size 360x640
- Output: Ground truth image at 720x1280
- Loss Function: L1 + 0.01 * Perceptual (VGG16)
- Optimizer: Adam
- Checkpoint saving after each epoch

Inference (Live Mode)

Uses `mss` to grab screen frames in real time and applies the ONNX model for upscaling. Final sharpening is performed with edge detection + kernel filter.

Modify monitored screen area:

monitor = {"top": 200, "left": 500, "width": 640, "height": 360}

Change coordinates to match your screen layout.

Notes

- Uses `torch_directml.device()` to utilize AMD GPU for training.
- Uses `DmlExecutionProvider` for ONNX inference.
- Tested on AMD Radeon Pro 5500M.
- For non-AMD users (NVIDIA or CPU-only):
  You can modify the runtime providers to use standard torch (CUDA) or onnxruntime (CPU/GPU) for broader compatibility. 
  Some minor changes in the device configuration and execution provider setup will be needed.
